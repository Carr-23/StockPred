{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StockPred.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBHmyOiwwA7a04K5zIjHZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Carr-23/StockPred/blob/master/StockPred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJUJdzjMxNq1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7ad0f6-5728-402e-e2e4-95c06fe9258e"
      },
      "source": [
        "!pip install yahoofinancials\n",
        "!pip install yfinance\n",
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yahoofinancials\n",
            "  Downloading https://files.pythonhosted.org/packages/97/fe/be0f6ea704137848779fc61e7d1c9a901489aaf3423cd7b6f86a350c14c6/yahoofinancials-1.6.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from yahoofinancials) (4.6.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from yahoofinancials) (2018.9)\n",
            "Building wheels for collected packages: yahoofinancials\n",
            "  Building wheel for yahoofinancials (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yahoofinancials: filename=yahoofinancials-1.6-cp37-none-any.whl size=15192 sha256=364aac9cc868a34cb224ee9e8ceaafd32b61129543ccd63531fade8da3a97b82\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/7e/cf/4977a8572d5247242a4b13018d1d36923024ba84236e0d28bc\n",
            "Successfully built yahoofinancials\n",
            "Installing collected packages: yahoofinancials\n",
            "Successfully installed yahoofinancials-1.6\n",
            "Collecting yfinance\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/ee/315752b9ef281ba83c62aa7ec2e2074f85223da6e7e74efb4d3e11c0f510/yfinance-0.1.59.tar.gz\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from yfinance) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.7/dist-packages (from yfinance) (2.23.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance) (0.0.9)\n",
            "Collecting lxml>=4.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/4d/6537313bf58fe22b508f08cf3eb86b29b6f9edf68e00454224539421073b/lxml-4.6.3-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5MB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24->yfinance) (2.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20->yfinance) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24->yfinance) (1.15.0)\n",
            "Building wheels for collected packages: yfinance\n",
            "  Building wheel for yfinance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yfinance: filename=yfinance-0.1.59-py2.py3-none-any.whl size=23442 sha256=a40c872bd2a1bff03e62c65a78575ae86cee257e5f8f02d375516e6ed1c65879\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/2a/0f/4b5a86e1d52e451757eb6bc17fd899629f0925c777741b6d04\n",
            "Successfully built yfinance\n",
            "Installing collected packages: lxml, yfinance\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed lxml-4.6.3 yfinance-0.1.59\n",
            "Requirement already up-to-date: tensorflow in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow) (54.2.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CLnHQN8FW35"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense, LSTM, Dropout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpiEnCpYJ98M"
      },
      "source": [
        "# Get Data\n",
        "amd_stock = yf.Ticker('AMD')\n",
        "amd_historyAll = amd_stock.history(period=\"5y\").reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tUcN-9bdhdE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "867092c7-eddc-4e0a-f576-91864c7d7225"
      },
      "source": [
        "# Delete date since numbers are just fine\n",
        "amd_historyAll.pop('Date')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      2016-04-18\n",
              "1      2016-04-19\n",
              "2      2016-04-20\n",
              "3      2016-04-21\n",
              "4      2016-04-22\n",
              "          ...    \n",
              "1254   2021-04-12\n",
              "1255   2021-04-13\n",
              "1256   2021-04-14\n",
              "1257   2021-04-15\n",
              "1258   2021-04-16\n",
              "Name: Date, Length: 1259, dtype: datetime64[ns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ekAhn1hdhus"
      },
      "source": [
        "# Round Data to be divisible by 50\n",
        "rounded = 50 * round(len(amd_historyAll)/50)\n",
        "limitOfDelete = len(amd_historyAll) - rounded\n",
        "tempList = list(range(0,limitOfDelete))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCKi_n7AOz_l"
      },
      "source": [
        "This is if we turn to numpy array early"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Wv_lEqTdh9C"
      },
      "source": [
        "amd_historyAll = amd_historyAll.drop(amd_historyAll.index[tempList])\n",
        "amd_historyAll = amd_historyAll.reset_index()\n",
        "amd_historyAll.pop('index')\n",
        "amd_historyAll.pop('Dividends')\n",
        "amd_historyAll.pop('Stock Splits')\n",
        "\n",
        "amd_historyAllX = amd_historyAll.copy()\n",
        "amd_historyAllX.pop('Close')\n",
        "\n",
        "amd_historyAllY = amd_historyAll.copy()\n",
        "amd_historyAllY.pop('Open')\n",
        "amd_historyAllY.pop('High')\n",
        "amd_historyAllY.pop('Low')\n",
        "amd_historyAllY.pop('Volume')\n",
        "\n",
        "amd_historyAllX = amd_historyAllX.to_numpy()\n",
        "amd_historyAllY = amd_historyAllY.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNo9kAoKdiAo"
      },
      "source": [
        "# Splitting Data by 50 history points\n",
        "\n",
        "xtrainingAll = []\n",
        "xtestingAll = []\n",
        "\n",
        "ytrainingAll = []\n",
        "ytestingAll = []\n",
        "\n",
        "for x in range(50, amd_historyAll.shape[0]):\n",
        "    if x%50 == 0:\n",
        "      xtestingAll.append(amd_historyAllX[x-50:x])\n",
        "      ytestingAll.append(amd_historyAllY[x,0])\n",
        "    else:      \n",
        "      xtrainingAll.append(amd_historyAllX[x-50:x])\n",
        "      ytrainingAll.append(amd_historyAllY[x,0])\n",
        "\n",
        "xHistory = [xtrainingAll,xtestingAll]\n",
        "yHistory = [ytrainingAll,ytestingAll]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcxgoLhxO4yq"
      },
      "source": [
        "This is if we turn to numpy array later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeS5qYXWO-Su",
        "outputId": "a5160e1f-afa6-4b50-bac9-753ac39b5cf9"
      },
      "source": [
        "# Drop Date (useless information that the model doesn't need to know)\n",
        "amd_historyAll = amd_historyAll.drop(amd_historyAll.index[tempList])\n",
        "amd_historyAll = amd_historyAll.reset_index()\n",
        "amd_historyAll.pop('index')\n",
        "amd_historyAll.pop('Dividends')\n",
        "amd_historyAll.pop('Stock Splits')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0\n",
              "1       0\n",
              "2       0\n",
              "3       0\n",
              "4       0\n",
              "       ..\n",
              "1245    0\n",
              "1246    0\n",
              "1247    0\n",
              "1248    0\n",
              "1249    0\n",
              "Name: Stock Splits, Length: 1250, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Ux4apWPDsa"
      },
      "source": [
        "# Creating blank variables\n",
        "xtrainingAll = pd.DataFrame(columns=['Open', 'High', 'Low','Close', 'Volume'])\n",
        "xtestingAll = pd.DataFrame(columns=['Open', 'High', 'Low','Close', 'Volume'])\n",
        "\n",
        "ytrainingAll = pd.DataFrame(columns=['Open', 'High', 'Low','Close', 'Volume'])\n",
        "ytestingAll = pd.DataFrame(columns=['Open', 'High', 'Low','Close', 'Volume'])\n",
        "\n",
        "# Splitting Data by 50 history points\n",
        "for x in range(50, amd_historyAll.shape[0]):\n",
        "    if x%50 == 0:\n",
        "      xtrainingAll = xtrainingAll.append(amd_historyAll.loc[x-50:x])\n",
        "      xtestingAll = xtestingAll.append(amd_historyAll.iloc[x:x+1])\n",
        "    else:      \n",
        "      ytrainingAll = ytrainingAll.append(amd_historyAll.loc[x-50:x])\n",
        "      ytestingAll = ytestingAll.append(amd_historyAll.iloc[x:x+1])\n",
        "\n",
        "xHistory = [xtrainingAll,xtestingAll]\n",
        "yHistory = [ytrainingAll,ytestingAll]\n",
        "\n",
        "# Deleting the useless columns\n",
        "for x in xHistory:\n",
        "  x.pop('Close')\n",
        "\n",
        "for y in yHistory:\n",
        "  y.pop('Open')\n",
        "  y.pop('High')\n",
        "  y.pop('Low')\n",
        "  y.pop('Volume')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guZHvH65hHhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aecc203-7851-4dd7-a6b0-d6930ce828d7"
      },
      "source": [
        "xtrainingAll1,xtestingAll1 = np.array(xtrainingAll),np.array(xtestingAll)\n",
        "ytrainingAll1,ytestingAll1 = np.array(ytrainingAll),np.array(ytestingAll)\n",
        "\n",
        "print(xtrainingAll)\n",
        "print(ytrainingAll)\n",
        "\n",
        "# Standarizing Data\n",
        "std = StandardScaler()\n",
        "xtrainingAll2 = std.fit_transform(xtrainingAll1)\n",
        "xtestingAll2 = std.transform(xtestingAll1)\n",
        "\n",
        "# Normalize, but wont change distribution and weights\n",
        "scaler = MinMaxScaler(feature_range=(-1,1))\n",
        "xtrainingAll3 = scaler.fit_transform(xtrainingAll2)\n",
        "xtestingAll3 = scaler.transform(xtestingAll2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "           Open       High        Low    Volume\n",
            "0      3.690000   3.690000   3.450000  17717800\n",
            "1      3.580000   3.750000   3.570000  16972800\n",
            "2      3.700000   3.710000   3.580000  13784800\n",
            "3      3.540000   3.670000   3.540000   8688500\n",
            "4      3.640000   3.800000   3.610000  21529600\n",
            "...         ...        ...        ...       ...\n",
            "1196  87.559998  88.330002  85.019997  56631200\n",
            "1197  86.830002  87.949997  84.660004  42359300\n",
            "1198  88.489998  89.279999  86.949997  33850000\n",
            "1199  88.599998  89.480003  87.339996  32312900\n",
            "1200  88.220001  88.599998  87.059998  30791600\n",
            "\n",
            "[1224 rows x 4 columns]\n",
            "          Close\n",
            "1      3.740000\n",
            "2      3.600000\n",
            "3      3.600000\n",
            "4      3.660000\n",
            "5      3.680000\n",
            "...         ...\n",
            "1245  78.580002\n",
            "1246  80.190002\n",
            "1247  78.550003\n",
            "1248  83.010002\n",
            "1249  82.150002\n",
            "\n",
            "[59976 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "9e92SKEojs_K",
        "outputId": "fd4a9193-7a13-4d72-be59-1c6634961ce2"
      },
      "source": [
        "print(xtrainingAll1.shape)\n",
        "print(xtrainingAll)\n",
        "# print(xtrainingAll)\n",
        "# print(xtrainingAll1)\n",
        "# print(xtrainingAll2)\n",
        "# print(xtrainingAll3)\n",
        "# print('---------------------------------------')\n",
        "# print(xtestingAll.shape)\n",
        "# print(xtestingAll)\n",
        "# print(xtestingAll1)\n",
        "# print(xtestingAll2)\n",
        "# print(xtestingAll3)\n",
        "# print('---------------------------------------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-4aa115628231>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrainingAll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrainingAll\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(xtrainingAll)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(xtrainingAll1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(xtrainingAll2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUL9BT7ksMCI",
        "outputId": "cd169ffe-6d40-41eb-d8e9-01917e8b6ede"
      },
      "source": [
        "print(xtrainingAll3.shape)\n",
        "print(xvalidationAll3.shape)\n",
        "print(xtestingAll3.shape)\n",
        "\n",
        "print(ytrainingAll.shape)\n",
        "print(yvalidationAll.shape)\n",
        "print(ytestingAll.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(540, 4)\n",
            "(90, 4)\n",
            "(150, 4)\n",
            "(540, 1)\n",
            "(90, 1)\n",
            "(150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YXxD_CxdiCU",
        "outputId": "0482ceaa-5201-4f29-e975-c7da6021b466"
      },
      "source": [
        "# Print Statements\n",
        "xtestingAll,xvalidationAll,xtestingAll = np.array(testingAll),np.array(validationAll),np.array(testingAll)\n",
        "print(\"--------------------Train------------------------\")\n",
        "print(trainingAll)\n",
        "print(\"--------------------Val------------------------\")\n",
        "print(validationAll)\n",
        "print(\"--------------------Test------------------------\")\n",
        "print(testingAll)\n",
        "\n",
        "print(\"--------------------OG------------------------\")\n",
        "print(amd_historyAll)\n",
        "print(\"--------------------OG------------------------\")\n",
        "print(amd_historyAll.iloc[0:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------Train------------------------\n",
            "[[0.00148063 0.00291676 0.00449878 ... 0.14068803 0.         0.        ]\n",
            " [0.         0.         0.         ... 0.36741887 0.         0.        ]\n",
            " [0.00922551 0.01234013 0.01211211 ... 0.6395115  0.         0.        ]\n",
            " ...\n",
            " [0.79806374 0.78808609 0.78890295 ... 0.11817898 0.         0.        ]\n",
            " [0.76867884 0.77080997 0.7710232  ... 0.13452759 0.         0.        ]\n",
            " [0.7493166  0.75005603 0.75441226 ... 0.13940929 0.         0.        ]]\n",
            "--------------------Val------------------------\n",
            "[[0.06548975 0.07213372 0.07174991 0.07550834 0.36567459 0.\n",
            "  0.        ]\n",
            " [0.07471527 0.07516267 0.06944284 0.0747087  0.47918127 0.\n",
            "  0.        ]\n",
            " [0.06833712 0.07213372 0.07221132 0.07573681 0.30293066 0.\n",
            "  0.        ]\n",
            " [0.06970387 0.08133273 0.07578727 0.08453279 0.43575475 0.\n",
            "  0.        ]\n",
            " [0.07733485 0.08077183 0.07786364 0.07973498 0.37719173 0.\n",
            "  0.        ]\n",
            " [0.07710706 0.07897688 0.07855578 0.07779301 0.29630766 0.\n",
            "  0.        ]\n",
            " [0.12676538 0.1371999  0.13357941 0.14370574 0.48114837 0.\n",
            "  0.        ]\n",
            " [0.14635535 0.15604666 0.15122851 0.16301119 0.73423145 0.\n",
            "  0.        ]\n",
            " [0.16947608 0.19306707 0.1738378  0.17763308 1.53365788 0.\n",
            "  0.        ]\n",
            " [0.17596811 0.18050258 0.16703196 0.17523417 0.99009435 0.\n",
            "  0.        ]\n",
            " [0.16287016 0.17186447 0.16668589 0.17694769 0.62926117 0.\n",
            "  0.        ]\n",
            " [0.17346242 0.17478124 0.17533741 0.17340644 0.43222292 0.\n",
            "  0.        ]\n",
            " [0.11993166 0.12306483 0.11431536 0.12017363 0.532596   0.\n",
            "  0.        ]\n",
            " [0.11457859 0.11319273 0.1075095  0.11640392 0.45415402 0.\n",
            "  0.        ]\n",
            " [0.10751708 0.12968363 0.11443072 0.12531415 0.63807708 0.\n",
            "  0.        ]\n",
            " [0.12938496 0.13607807 0.13277194 0.13856523 0.51930523 0.\n",
            "  0.        ]\n",
            " [0.1333713  0.13450751 0.1316184  0.13125429 0.37641931 0.\n",
            "  0.        ]\n",
            " [0.12198178 0.12452322 0.12169801 0.12931232 0.34415531 0.\n",
            "  0.        ]\n",
            " [0.10740318 0.11689477 0.10912447 0.1204021  0.339767   0.\n",
            "  0.        ]\n",
            " [0.11742597 0.12295264 0.12065982 0.12634225 0.35524819 0.\n",
            "  0.        ]\n",
            " [0.11867881 0.12149427 0.11696851 0.11480466 0.30741447 0.\n",
            "  0.        ]\n",
            " [0.11355353 0.11655821 0.11523819 0.11526159 0.30392093 0.\n",
            "  0.        ]\n",
            " [0.11389521 0.12250392 0.12089054 0.12725612 0.40151569 0.\n",
            "  0.        ]\n",
            " [0.12448746 0.1339466  0.12954205 0.13959333 0.4652096  0.\n",
            "  0.        ]\n",
            " [0.18633257 0.18476552 0.18768024 0.19019877 0.23025522 0.\n",
            "  0.        ]\n",
            " [0.18735763 0.18745791 0.19067943 0.19465387 0.18230113 0.\n",
            "  0.        ]\n",
            " [0.20455581 0.2227956  0.21132771 0.22058488 0.89996712 0.\n",
            "  0.        ]\n",
            " [0.21435078 0.21651333 0.21974853 0.22138451 0.32570481 0.\n",
            "  0.        ]\n",
            " [0.22300682 0.21987884 0.22194023 0.22012794 0.24349724 0.\n",
            "  0.        ]\n",
            " [0.21218679 0.21157729 0.21478833 0.21498744 0.20539758 0.\n",
            "  0.        ]\n",
            " [0.2498861  0.25218756 0.25793055 0.25668266 0.19692336 0.\n",
            "  0.        ]\n",
            " [0.25432801 0.25140228 0.24801014 0.24765821 0.23301911 0.\n",
            "  0.        ]\n",
            " [0.23507973 0.23412607 0.23601338 0.23589217 0.26692494 0.\n",
            "  0.        ]\n",
            " [0.22995444 0.22840476 0.22632368 0.22264109 0.26937549 0.\n",
            "  0.        ]\n",
            " [0.22437357 0.23423826 0.23093782 0.23692027 0.34686002 0.\n",
            "  0.        ]\n",
            " [0.23473804 0.23221898 0.23647479 0.23749143 0.23141708 0.\n",
            "  0.        ]\n",
            " [0.24715262 0.24489566 0.24708731 0.25348412 0.15399621 0.\n",
            "  0.        ]\n",
            " [0.24191343 0.24388601 0.22886145 0.22652503 0.33311565 0.\n",
            "  0.        ]\n",
            " [0.2309795  0.23143368 0.23509056 0.2349783  0.16864181 0.\n",
            "  0.        ]\n",
            " [0.23394077 0.2333408  0.23116853 0.23406444 0.18165654 0.\n",
            "  0.        ]\n",
            " [0.2261959  0.23659411 0.23232207 0.24068998 0.19462152 0.\n",
            "  0.        ]\n",
            " [0.24384965 0.24388601 0.25112469 0.24834362 0.137856   0.\n",
            "  0.        ]\n",
            " [0.27687925 0.27944805 0.28307761 0.28763993 0.23641417 0.\n",
            "  0.        ]\n",
            " [0.28621866 0.2957146  0.29069095 0.30363264 0.33143802 0.\n",
            "  0.        ]\n",
            " [0.30182233 0.30390396 0.30476409 0.30203337 0.33892246 0.\n",
            "  0.        ]\n",
            " [0.29612757 0.29605114 0.29945784 0.29952022 0.17392688 0.\n",
            "  0.        ]\n",
            " [0.30136674 0.3017725  0.30534085 0.30351838 0.18723207 0.\n",
            "  0.        ]\n",
            " [0.29612757 0.29717299 0.30499481 0.30363264 0.11264473 0.\n",
            "  0.        ]\n",
            " [0.43473803 0.43740184 0.44480331 0.44368288 0.11685249 0.\n",
            "  0.        ]\n",
            " [0.44544416 0.45120036 0.4548391  0.45761938 0.20985602 0.\n",
            "  0.        ]\n",
            " [0.4571754  0.45950188 0.46533627 0.47087046 0.20400494 0.\n",
            "  0.        ]\n",
            " [0.46583142 0.46802782 0.47456455 0.47224125 0.1610942  0.\n",
            "  0.        ]\n",
            " [0.47346242 0.4688131  0.48033222 0.47658214 0.11969895 0.\n",
            "  0.        ]\n",
            " [0.47015945 0.4673547  0.47502597 0.47978066 0.11653169 0.\n",
            "  0.        ]\n",
            " [0.41298405 0.42506168 0.41919485 0.42117891 0.28794486 0.\n",
            "  0.        ]\n",
            " [0.42346243 0.43044646 0.4279617  0.43580078 0.25754252 0.\n",
            "  0.        ]\n",
            " [0.43132118 0.43123174 0.41065866 0.4086132  0.33213384 0.\n",
            "  0.        ]\n",
            " [0.38861048 0.41238498 0.38758795 0.38782271 0.37490482 0.\n",
            "  0.        ]\n",
            " [0.37972666 0.39477224 0.38689582 0.39730411 0.30995305 0.\n",
            "  0.        ]\n",
            " [0.38997721 0.3898362  0.37074634 0.37559973 0.31149938 0.\n",
            "  0.        ]\n",
            " [0.48849659 0.52019292 0.49786597 0.53324194 0.31440453 0.\n",
            "  0.        ]\n",
            " [0.53690205 0.54868744 0.54758333 0.54523645 0.30843756 0.\n",
            "  0.        ]\n",
            " [0.52255123 0.52266097 0.49878878 0.49257484 0.30841767 0.\n",
            "  0.        ]\n",
            " [0.51195897 0.51054517 0.4908294  0.50022847 0.27098399 0.\n",
            "  0.        ]\n",
            " [0.48428248 0.50078526 0.49428999 0.51370802 0.19912174 0.\n",
            "  0.        ]\n",
            " [0.52004557 0.51581779 0.50790172 0.51119487 0.17031895 0.\n",
            "  0.        ]\n",
            " [0.81685647 0.80502575 0.81774134 0.81539863 0.10346076 0.\n",
            "  0.        ]\n",
            " [0.79362184 0.81613186 0.80239938 0.83458986 0.13052524 0.\n",
            "  0.        ]\n",
            " [0.83405467 0.83374468 0.83827435 0.84647016 0.15704211 0.\n",
            "  0.        ]\n",
            " [0.8484055  0.8440655  0.84196566 0.83813116 0.10609037 0.\n",
            "  0.        ]\n",
            " [0.83485194 0.85853713 0.83965854 0.87548547 0.16178753 0.\n",
            "  0.        ]\n",
            " [0.87596812 0.87087725 0.87253428 0.87171575 0.15145663 0.\n",
            "  0.        ]\n",
            " [0.75956719 0.77507289 0.76975431 0.78032895 0.17944273 0.\n",
            "  0.        ]\n",
            " [0.76343959 0.75846976 0.7459915  0.74914326 0.17230495 0.\n",
            "  0.        ]\n",
            " [0.7493166  0.74321285 0.74056987 0.74240344 0.14451034 0.\n",
            "  0.        ]\n",
            " [0.73883827 0.75151446 0.75025953 0.76387939 0.12198487 0.\n",
            "  0.        ]\n",
            " [0.79943052 0.80502575 0.80066906 0.81836873 0.24805814 0.\n",
            "  0.        ]\n",
            " [0.83382683 0.82353598 0.83389086 0.83721727 0.14839779 0.\n",
            "  0.        ]\n",
            " [1.         0.99708322 0.97485292 0.97840988 0.25349242 0.\n",
            "  0.        ]\n",
            " [0.94476084 0.94009419 0.93759368 0.93751427 0.21887834 0.\n",
            "  0.        ]\n",
            " [0.93063777 0.92293019 0.9330949  0.92620517 0.18254683 0.\n",
            "  0.        ]\n",
            " [0.91902049 0.91429205 0.90321837 0.89673291 0.16231425 0.\n",
            "  0.        ]\n",
            " [0.90546694 0.89174331 0.89606642 0.91089784 0.1412993  0.\n",
            "  0.        ]\n",
            " [0.91674262 0.90520525 0.91175451 0.90290153 0.09191378 0.\n",
            "  0.        ]\n",
            " [0.7493166  0.75005603 0.75441226 0.75976698 0.13940929 0.\n",
            "  0.        ]\n",
            " [0.75808659 0.75622613 0.75521973 0.77336079 0.16116582 0.\n",
            "  0.        ]\n",
            " [0.76275624 0.76205961 0.76940826 0.77027644 0.10165481 0.\n",
            "  0.        ]\n",
            " [0.75637814 0.7456809  0.75314337 0.75725383 0.11172658 0.\n",
            "  0.        ]\n",
            " [0.75751707 0.77451194 0.77240739 0.7858122  0.13405956 0.\n",
            "  0.        ]\n",
            " [0.7984055  0.79896786 0.80655212 0.81539863 0.11657347 0.\n",
            "  0.        ]]\n",
            "--------------------Test------------------------\n",
            "[[0.07710706 0.07897688 0.07855578 ... 0.29630766 0.         0.        ]\n",
            " [0.07505694 0.07606014 0.0680586  ... 0.39258787 0.         0.        ]\n",
            " [0.06514806 0.06529055 0.06921214 ... 0.2116376  0.         0.        ]\n",
            " ...\n",
            " [0.79282457 0.7923491  0.80078444 ... 0.10475343 0.         0.        ]\n",
            " [0.79521636 0.78573025 0.78878766 ... 0.08732802 0.         0.        ]\n",
            " [0.80022778 0.82858418 0.81220442 ... 0.25946784 0.         0.        ]]\n",
            "--------------------OG------------------------\n",
            "          Open       High        Low  ...     Volume  Dividends  Stock Splits\n",
            "0    10.190000  10.350000   9.950000  ...   44992200          0             0\n",
            "1    10.060000  10.090000   9.560000  ...   90578000          0             0\n",
            "2    10.870000  11.190000  10.610000  ...  145284100          0             0\n",
            "3    11.200000  11.360000  11.020000  ...   74347800          0             0\n",
            "4    11.060000  11.140000  10.870000  ...   50608800          0             0\n",
            "..         ...        ...        ...  ...        ...        ...           ...\n",
            "745  82.800003  83.589996  82.160004  ...   32730300          0             0\n",
            "746  82.059998  82.180000  78.029999  ...   62098800          0             0\n",
            "747  79.669998  80.720001  78.980003  ...   37767300          0             0\n",
            "748  79.879997  80.129997  77.940002  ...   34263800          0             0\n",
            "749  80.320000  83.949997  79.970001  ...   68873700          0             0\n",
            "\n",
            "[750 rows x 7 columns]\n",
            "--------------------OG------------------------\n",
            "    Open   High    Low  Close     Volume  Dividends  Stock Splits\n",
            "0  10.19  10.35   9.95  10.09   44992200          0             0\n",
            "1  10.06  10.09   9.56   9.71   90578000          0             0\n",
            "2  10.87  11.19  10.61  11.04  145284100          0             0\n",
            "3  11.20  11.36  11.02  11.11   74347800          0             0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}